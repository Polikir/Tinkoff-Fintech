{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Альтернативный подход к задачам мультиклассовой классификации:\n",
    "\n",
    "Вместо того, чтобы предсказывать таргет напрямую, мы можем закодировать таргет в двоичном коде и предсказывать каждый бит по отдельности.\n",
    "\n",
    "Тогда нам понадобится всего $~ \\text{log}_2(L + 1)$ классификаторов на L + 1 класс.\n",
    "\n",
    "Попробуем обучить набор таких логрегов и сравнить качество полученного классификатора с мультиномиальной и OvR регрессиями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт базовых библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set();\n",
    "import scipy.stats as sps\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг 0: импорт и препроцессинг данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.4 s, sys: 1min 22s, total: 2min 17s\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mnist = fetch_openml(data_id=554) # https://www.openml.org/d/554\n",
    "# генерируем сегментирующую случайную переменую\n",
    "rn = pd.Series(sps.randint.rvs(1, 101, size = len(mnist.data), random_state = 42))\n",
    "# разбиваем на трейн/валидацию/тест\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "train_mask, val_mask, test_mask = (rn <= 60), ((rn > 60) & (rn <= 70)), (rn > 70)\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = X[train_mask], y[train_mask], X[test_mask], y[test_mask], X[val_mask], y[val_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нормируем данные\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг 1: учим классификаторы с семинара"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вообще говоря, мы можем научить классификаторы с базовыми гиперпараметрами -- на семинаре мы видели, что они показывают на нашей задаче неплохое качество, но ведь нет предела совершенству -- давайте подберём какие-нибудь гиперпараметры для логрега (список можно посмотреть тут: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Автоматизировать подбор гиперпараметров , как правило, удобнее -- ручной подбор предпочтителен для понимания, что и как влияет на качество моделей, но обычно занимает слишком много времени и сил без каких-либо преимуществ над автоматическим отбором"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем функцию grid_search, которая будет делать следующее: принимая обучающую и валидационную выборки, функция обучает набор из классификаторов со всевозможными комбинациями гиперпараметров (предварительно указанных нами для перебора в словаре) и выбирает из них тот, чьё качество по целевой метрике на валидационной выборке оказывается наилучшим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Вопрос для размышления:}$ можно ли тут попробовать \"встроить\" защиту от переобучения?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#реализуем функцию для подбора гиперпараметров модели\n",
    "#для перехода от словаря параметров к списку комбинаций может быть полезен sklearn.model_selection.ParameterGrid\n",
    "def grid_search(X_train, X_val, y_train, y_val, params_dict):\n",
    "    '''\n",
    "    Функция подбирает гиперпараметры мультиномиальной логитиеской регрессии для получения максимального значения accuracy\n",
    "    на валидационной выборке, принимает:\n",
    "    X_train -- DataFrame независимых переменных на обучающей выборке\n",
    "    X_val -- DataFrame независимых переменных на валидационной выборке\n",
    "    y_train -- Series таргета на обучающей выборке\n",
    "    y_val -- Series таргета на валидационной выборке\n",
    "    params_dict -- словарь гиперпараметров в формате {'paramater_nm':[value_1, value_2, ...]}\n",
    "    '''\n",
    "    best_score = 0\n",
    "    i = 0\n",
    "    for collection in ParameterGrid(params_dict):\n",
    "        clf = LogisticRegression(**collection,\n",
    "                                 multi_class='multinomial',\n",
    "                                 max_iter=1000,\n",
    "                                 fit_intercept=True)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        score = roc_auc_score(y_val, clf.predict_proba(X_val), average='macro', multi_class = 'ovr')\n",
    "        score1 = accuracy_score(y_val, clf.predict(X_val))\n",
    "        if best_score < score:\n",
    "            best_score = score\n",
    "            best_parametrs = collection\n",
    "\n",
    "        print(i,collection,'Score:', score,'Best_score:',best_score,'Accuracy:',score1)\n",
    "        i += 1\n",
    "    return (best_parametrs)  #ну или best_parameters, если вдруг так интереснее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала я подбирал параметры с большим размахом, а потом выделил интервал [0.005:0.05], на котором результат был лучше всего и рассмотрел его более подробно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут обучаем свой классификатор -- можно просто .fit() без подбора параметров, можно -- с подбором\n",
    "grid = {\n",
    "    'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
    "    \n",
    "}\n",
    "grid_search(\n",
    "    X_train,\n",
    "    X_val,\n",
    "    y_train,\n",
    "    y_val,\n",
    "    grid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "grid = {\n",
    "    'C': np.linspace(0.001,0.05,10),\n",
    "    \n",
    "}\n",
    "grid_search(\n",
    "    X_train,\n",
    "    X_val,\n",
    "    y_train,\n",
    "    y_val,\n",
    "    grid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одним из лучших по roc и accuracy оказался параметр C = 0.02 и roc = 0.993 , acc = 0.92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг 2: бинаризуем таргет и учим классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_bin(x):\n",
    "    x = int(x)\n",
    "    b = []\n",
    "    while x > 0:\n",
    "        b = [x % 2] + b\n",
    "        x = x // 2\n",
    "    for i in range(4 - len(b)):\n",
    "        b.insert(0, 0)\n",
    "    return np.array(b)\n",
    "\n",
    "\n",
    "def make_binary_predictors(y):\n",
    "    '''\n",
    "    Функция принимает Series y c категориальной переменной и делает DataFrame с [log_2(L+1)] столбцами из 0 и 1\n",
    "    \n",
    "    подсказка: в нашем конкретном случае можно переводить десятичное число в двоичное \n",
    "    '''\n",
    "\n",
    "    targets = pd.DataFrame(np.concatenate(y.astype('object').apply(num_to_bin).values).reshape(-1,4))\n",
    "    targets.columns = ['tar0', 'tar1', 'tar2', 'tar3']\n",
    "    return (targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_norm(x):\n",
    "    x = list(x)\n",
    "    s = 0\n",
    "    for i in range(len(x)):\n",
    "        s += x[i]\n",
    "    for i in range(len(x)):\n",
    "        x[i] /= s\n",
    "    return x\n",
    "def softmax(x):\n",
    "    \n",
    "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "class BinarisedTargetClassifier():\n",
    "    '''\n",
    "    класс BinarisedTargetClassifier -- мультиклассовый классификатор на основании нескольких бинарных логистических регрессий\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X_train, y_train):\n",
    "\n",
    "        self.clf0 = LogisticRegression(fit_intercept=True, max_iter=1000)\n",
    "        self.clf1 = LogisticRegression(fit_intercept=True, max_iter=1000)\n",
    "        self.clf2 = LogisticRegression(fit_intercept=True, max_iter=1000)\n",
    "        self.clf3 = LogisticRegression(fit_intercept=True, max_iter=1000)\n",
    "\n",
    "        self.clf0.fit(X_train, y_train['tar0'])\n",
    "        self.clf1.fit(X_train, y_train['tar1'])\n",
    "        self.clf2.fit(X_train, y_train['tar2'])\n",
    "        self.clf3.fit(X_train, y_train['tar3'])\n",
    "\n",
    "    def predict(self,X):\n",
    "        predictions = (lambda x: 8*x[0] + 4*x[1] + 2*x[2] + x[3])(np.concatenate([\n",
    "            self.clf0.predict(X),\n",
    "            self.clf1.predict(X),\n",
    "            self.clf2.predict(X),\n",
    "            self.clf3.predict(X)\n",
    "        ]).transpose().reshape(4,-1))\n",
    "        \n",
    "        return list(map(str,list(predictions)))\n",
    "\n",
    "    def predict_score(self,X):  #(без него не построить AUC, но в целом обойтись можно)\n",
    "        end_preds = np.array([])\n",
    "        \n",
    "        preds = [\n",
    "        self.clf0.predict_proba(X),\n",
    "        self.clf1.predict_proba(X),\n",
    "        self.clf2.predict_proba(X),\n",
    "        self.clf3.predict_proba(X)]\n",
    "        \n",
    "        for x in ['0000','0001','0010','0011','0100','0101','0110','0111','1000','1001']:\n",
    "            ptr = np.ones(X.shape[0])\n",
    "            t = 0\n",
    "            for i in x:\n",
    "                ptr = ptr * preds[t][:,int(i)]\n",
    "                t+=1\n",
    "            end_preds = np.concatenate([end_preds,ptr])\n",
    "            \n",
    "        end_preds = end_preds.reshape(-1,10)\n",
    "        end_preds = np.apply_along_axis(softmax , 1, end_preds)\n",
    "        return end_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#учим созданный классификатор\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf_bin = BinarisedTargetClassifier()\n",
    "#обучаем\n",
    "clf_bin.fit(X_train, make_binary_predictors(y_train))\n",
    "#предсказываем класс, считаем accuracy\n",
    "y_pred = clf_bin.predict(X_test)\n",
    "accuracy_bin = accuracy_score(y_test, y_pred)\n",
    "#предсказываем вероятность, считаем AUC\n",
    "score_bin = clf_bin.predict_score(X_test)\n",
    "auc_bin = roc_auc_score(y_test, score_bin, average='macro', multi_class = 'ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг 3: сравнение качества полученных классификаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(multi_class='multinomial',\n",
    "                         max_iter=1000,\n",
    "                         fit_intercept=True,\n",
    "                         C=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.02, max_iter=1000, multi_class='multinomial')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test = clf.score(X_test, y_test)\n",
    "y_score = clf.predict_proba(X_test)\n",
    "auc_test = roc_auc_score(y_test, y_score, average='macro', multi_class = 'ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regression_type</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample</td>\n",
       "      <td>0.921090</td>\n",
       "      <td>0.992705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bin</td>\n",
       "      <td>0.711953</td>\n",
       "      <td>0.502715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  regression_type  accuracy  macro AUC\n",
       "0          sample  0.921090   0.992705\n",
       "1             bin  0.711953   0.502715"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(\n",
    "{'regression_type' : ['sample','bin'],\n",
    "'accuracy' : [accuracy_test,accuracy_bin],\n",
    "'macro AUC' : [auc_test,auc_bin]\n",
    "}\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Вывод}:$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мультиномиальная регргрессия показала значительно лучший результат чем побитовая, accuracy = 0.921  и auc = 0.992 против accuracy = 0.71 и auc = 0.5. Как мне кажется, такой исход был очевиден, потому ,что когда мы бинаризуем target, мы устанавливаем некотурую взаимосвязь между категориями, хотя очевидно, что зависимости значения числа от его написания нет, тем самым мы усложняем задачу для нашей модели из-за того, что накладываем на неё неправильные условия. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
